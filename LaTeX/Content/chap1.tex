Multi-target tracking is the problem of estimation the state of multiple dynamic objects, referred to as \textit{targets} over a fixed window of time. At various points of time within the window, the targets are observed in a \textit{scan}, resulting in a set of \textit{detections}. From these detections, the multi-target tracking problem aims to extract information about target dynamics. 

Solutions to this problem are sought across many civilian and military applications including but not limited to ballistic missile and aircraft defense, space applications, the movement of ships and ground troops, autonomous vehicles and robotics, and air traffic control. Each application has unique attributes and assumptions, and various algorithms have been developed for each. As a result, the field of multi-target tracking has expanded to numerous research venues, and there is a wide range of literature on the topic. A complete overview of all MTT methods, including the classes of algorithms and their variants as well as additional methods not discussed in this paper, can be found in \cite{MTT-Taxonomy}. For a more exhaustive overview of estimation techniques, filtering, gating, and more please see \cite{Bar-Shalom_MTT} and \cite{Bar-Shalom_Estimation}.

The field of multi-target tracking faces two primary challenges: (i) data association and (ii) trajectory estimation.  Given a set of sensor detections, the data association problem consists of assigning the detections to a set of targets. Alternatively, this can be viewed as a labeling problem in which each detection needs to be labeled with a target identifier. The association problem is further complicated when sensors fail to report detections (missed detection) or incorrectly report detections (false alarm), resulting in ambiguity in the number of existing targets. The trajectory estimation problem consists of estimating the state space of a target (\textit{i.e.}, position, velocity, acceleration, size, etc.) from the associated detections of the aforementioned assignment problem. Even when all of the associations are known, the estimation problem is challenging due to the presence of measurement noise. The two problems of data association and trajectory estimation are closely related and dependent on one another. 

Some classical algorithms treat the data association and trajectory estimation problems separately using a combination of probabilistic approaches to determine data associations and filters to estimate trajectories. One such algorithm is the global nearest neighbor (GNN). The GNN algorithm is a naive 2-D assignment algorithm, which evaluates one scan of detections at a time, globally assigning the nearest detection at each scan \cite{GNN}. Once the data association has been determined, the detections are often passed through one of numerous filters, most commonly a Kalman filter \cite{Kalman}, which updates the trajectory estimates before the algorithm progresses forward to the next scan. This process repeats sequentially through each scan of data.

Modern algorithms in the field of multi-target tracking are most commonly statistically based, often relying on heavy probabilistic assumptions about the underlying target dynamics or detection process. The two most prevalent statistical algorithms in the field of multi-target tracking are the Multiple Hypothesis Tracker (MHT) and the Joint Probability Data Association Filter (JPDAF) and their numerous variants and extensions. Both classes of algorithms attempt to solve the data association problem by generating a set of potential hypotheses, or possible detection-to-track assignments. Here a \textit{track} is a set of labeled detections belonging to the same target. Probabilities are assigned to each hypothesis based on the likelihood of the trajectory's existence, and numerous approaches for accomplishing this task have been proposed.

The MHT, first proposed by Reid in \cite{MHT-Seminal}, assigns likelihood values to hypotheses using a Bayesian maximum a posteriori estimator, which requires probabilistic assumptions on both object dynamics and detection process. This algorithm is generally considered to be the modern standard for solving the data association problem. Many variants have been proposed for implementation which leverage techniques such as clustering, gating, hypothesis selection, hypothesis pruning, and merging of state estimates. Many of these methods are summarized in \cite{MHT-Overview}. 

While the MHT has seen various forms of success, it faces several key challenges. Namely, the curse of dimensionality and complexity. The number of possible hypotheses grows exponentially with the number of potential tracks and the number of scans. Consequently, it is considered intractable for large scenarios. Moreover, the MHT might require extensive tuning and thus may be difficult to implement in practice, in addition to being computationally expensive. For these reasons, it is generally considered to be one of the most complex MTT algorithms. 

A Probability Data Association (PDA) takes a Bayesian approach to solving the data association problem by finding detection-to-target assignment probabilities via a posterior PDF, which again requires heavy assumptions on object dynamics and the detection process. In similar fashion, a Joint PDA (JPDA) assigns probabilities that are computed \textit{jointly} across all targets. The JPDAF is an algorithm which implements the JPDA along with filters and estimation methods as discussed previously in \cite{Bar-Shalom_MTT}.

A limited number of optimization based algorithms have been applied to solve the MTT problem, most of which attempt to solve by mapping the measurement set onto a trellis and seek the optimal measurement association sequence. Some examples include the Multi-Target Viterbi \cite{Viterbi-1} and an extension in \cite{Viterbi-2} which formulates \cite{Viterbi-1} as a network flow, reducing the solve time from exponential to polynomial. Still others, in particular \cite{Viterbi-3}, have suggested adaptations of this approach that output a single best set of tracks, or a list of best sets of tracks, similarly to the MHT.  

Compared to the number of statistically based algorithms in the MTT literature, optimization based algorithms are relatively scarce. In fact, most occurrences of optimization in the MTT literature propose the use of optimization to leverage statistical algorithms, in particular, the MHT. For example, integer optimization has been used to improve MHT hypothesis selection by solving an assignment problem which chooses the best hypothesis, but only after costs have been assigned (statistically based) and hypotheses have been pruned \cite{MHT-IP}. Somewhat similarly, linear optimization has also been used to assist in the hypothesis selection process for the MHT \cite{MHT-LP}. Still, other attempts aim to improve the MHT hypothesis selection process via Lagrangian relaxation \cite{Lagrangian}. 

More recently, Andriyenko and Schindler have proposed formulating the MTT problem as a minimization of a continuous energy \cite{Continuous_energy}, and then again as a minimization of discrete-continuous energy \cite{Discrete-Continuous_energy}. These algorithms aim to more accurately represent the nature of the problem, but sacrifice interpretability for complexity in the process. Rather than formulating the problem to lend it easily to traditional global optimization methods, the authors aim to leverage the use of optimization techniques to find strong local minima of their proposed energy objective, and they achieve strong results in doing so. However, this approach calls for the use of several parameters that must be tuned and few recommendations are provided for how to go about such a tuning process. Additionally, these methods require initialization heuristics to begin the solving process, which is in itself complicated to implement and is not directly connected to the optimization problem solved. 

In this paper, we propose the use of mixed integer optimization (MIO) to formulate and solve the multi-target tracking problem. Although MIOs are generally thought to be intractable (NP-Hard), in many practical cases near optimal solutions and even optimal solutions to these problems can be obtained very efficiently \cite{Computation}. This can be attributed to the fact that MIO solvers have seen significant performance improvements in recent years due to advancements in both methodology and hardware. The development of new heuristic methods, discoveries in cutting plane theory, and improved linear optimization methods have all contributed to improvements in performance \cite{Gurobi-MIP}. Modern solvers such as Gurobi and CPLEX have been shown to perform extremely well on benchmark tests. In the past six years alone, Gurobi has seen performance improvements by a factor of 48.7 \cite{Gurobi-Benchmark}. CPLEX saw improvements by a factor of 29,000 from 1991 to 2007 \cite{CPLEX-Benchmark}. From 1994 to 2014, the growth of supercomputing power as recorded by the TOP500 list has improved by a factor of 567839 \cite{Supercomputer}. Thus, the total combined effective improvement of software and hardware advancements is on the scale of 800 billion times in the past 25 years \cite{Dunn}. 

The literature is also lacking in performance metrics for the evaluation of MTT algorithms. There is no standard method of measuring scenario complexity or algorithm performance as a function of this complexity. In many cases, only the sensor's detection noise is taken into account and other factors such as target density are negated. Recent work \cite{MTT-Performance} proposes a mathematically rigorous performance metric for measuring the distance between ground truth and estimated track, but there is not much attention given to the complexity of generated scenarios. In this paper, we also suggest measures of complexity and performance which are related to the ones suggested in \cite{MTT-Performance}, but we show the value in relating a complexity measure to performance measures, namely that it allows us to evaluate the data association and trajectory estimation problems separately. We evaluate the methods suggested in this paper using these complexity and performance measures on two simulated experiments.

The main contributions of this paper are as follows: 
\begin{enumerate}[(i)]
\item We introduce a simple interpretable MIO model which solves the data association and trajectory estimation problems simultaneously for a sensor with no detection ambiguity. The model does not require assumptions on data generation or any tuning of parameters. This MIO is practically tractable, in the sense that it obtains high quality solutions in reasonable amount of time for the considered applications.
\item We propose a simple local search heuristic, motivated by the optimization problem, which provides feasible solutions to this problem and show how it can be used as warm start to the MIO in order to improve the quality of the solutions obtained as well as the running time. This heuristic is highly scalable and parallelizable, solving in milliseconds.
\item We extend this basic MIO model and corresponding heuristic initialization algorithm for the case of detection ambiguity, i.e., the case where there are both missed detections and false alarms, keeping interpretability while only adding two tunable parameters, as well as provide general guidelines as how to tune these parameters. 
\item  We present a new measure of complexity for the data association problem and show how it allows scenario generation and performance to be measured separately in each of their own natural demands. We also discuss a simplified measure of performance for the trajectory estimation problem. 
\end{enumerate}

The paper structure is as follows. We begin with a description of the MTT problem as we wish to model it in \mysection~\ref{\myabrv Problem Description}. In \mysection~\ref{\myabrv Basic MIO Model} we introduce a simple MIO formulation for a sensor with no detection ambiguity and extend it to a generalized formulation. Then we present a randomized local search heuristic in \mysection~\ref{\myabrv Heuristic}, which we use as a warm start for the MIO. In \mysection~\ref{\myabrv Robust MIO Model} we discuss extensions to both the MIO model and the heuristic for the case of detection ambiguity. In order to quantify the performance of our suggested methods, we develop metrics for measuring scenario complexity and algorithm performance in \mysection~\ref{\myabrv Scenario-Performance}.  Experimental methods and computational results are presented in \mysection~\ref{\myabrv Results}, including results for scenarios both with and without detection ambiguity. Finally, we summarize our contributions and identify future work in \mysection~\ref{\myabrv Conclusion}.

{\bf General Notations:}
Unless specified otherwise, $\|\cdot\|$ is used to indicate the $\ell_1$ norm, and $|\cdot|$ refers to element wise absolute value.