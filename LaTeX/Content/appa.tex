Here we provide recommendations for the tuning of the false alarm penalty $\theta$ and the missed detection penalty $\phi$. We begin with an explanation grounded in logic. It can be shown that the expected number of false alarms increases as the false alarm rate $\lambda$ increases. Therefore, it stands to reason that the false alarm penalty should decrease as the false alarm rate increases, as a general rule of thumb. Similarly, the expected number of missed detections increases as the missed detection probability $\gamma$ increases, and so too the missed detection penalty $\phi$ should decrease. Furthermore, there is reason to believe that the value of both of these penalties should be tied to the value of $\sigma$. Specifically, the estimation error (first term in \eqref{eq: general_objective}) will naturally increase as the noise $\sigma$ increases. Therefore, the values of $\theta$ and $\phi$ should be adjusted to account for this tradeoff. In particular, we should consider increasing both penalties as $\sigma$ increases. 

We also note that the number of false alarms is independent of the number of targets. In contrast, both the estimation error and number of missed detections are directly proportional to the number of targets. This presents a challenge because the true number of targets is unknown and we cannot tune the penalties to suit this number. Instead, we suggest normalizing $\theta$ for the number of targets the MIO is currently estimating. This effectively balances the terms in the objective function by making each term proportional to the number of targets. For example, we tuned $\theta$ for scenarios with eight targets and used the following linear dependence to update $\theta(P_{\text{est}})$ for the estimated number of targets $P_{\text{est}}$:
\begin{align}
\theta(P_{\text{est}})=\frac{P_{\text{est}}}{8}\theta.
\end{align}

Additionally, we empirically observed that the missed detection penalty $\phi$ benefits from tuning for $\gamma$, $\lambda$ and $\sigma$, while the false alarm penalty $\theta$  benefits from tuning for $\lambda$ and $\sigma$, but gains no added benefit from tuning for $\gamma$.

Through examination and experimentation we found these conclusions to generally hold true across a variety of scenario sizes and difficulties. Using the insight gained from these results, we tuned both penalties for the full scale experiment with detection ambiguity outlined in \mysection~\ref{\myabrv Results}. The false alarm penalties for the eight target scenarios in the robust experiment are shown in Table~\ref{tab:Theta_Penalties} and the missed detection penalties are shown in Table~\ref{tab:Phi_Penalties}.
\begin{table}[ht]
\centering
\begin{tabular}{c|m{1cm}m{1cm}m{1cm}m{1cm}}
  \hline
   & \multicolumn{4}{c}{$\sigma$} \\
   \cline{2-5}
   $\lambda$ & 0.1 & 0.5 & 1.0 & 2.0\\
  \hline
  \hline
   0.1 & 1.7 & 2.6 & 3.1 & 3.5 \\
   0.5 & 1.1 & 1.9 & 2.3 & 2.5 \\ 
   1.0 & 0.9 & 1.2 & 1.6 & 1.8 \\ 
   2.0 & 0.5 & 0.9 & 0.9 & 1.0 \\ 
   \hline
\end{tabular}
\caption{False alarm penalties ($\theta$) as a function of $\lambda$ and $\sigma$.}
\label{tab:Theta_Penalties}
\end{table}
\begin{table}[ht]
\centering
\begin{tabular}{cc|cccc}
  \hline
  & & \multicolumn{4}{c}{$\sigma$} \\
  \cline{3-6}
 $\lambda$ & $\gamma$ & 0.1 & 0.5 & 1 & 2 \\ 
  \hline
  \hline
   0.10 & 0.05 & 0.20 & 0.50 & 0.80 & 0.70 \\ 
   0.10 & 0.10 & 0.10 & 0.30 & 0.50 & 0.50 \\ 
   0.10 & 0.15 & 0.10 & 0.20 & 0.40 & 0.40 \\ 
   0.10 & 0.20 & 0.10 & 0.10 & 0.30 & 0.40 \\ 
   0.50 & 0.05 & 0.20 & 0.50 & 0.80 & 0.80 \\ 
   0.50 & 0.10 & 0.20 & 0.30 & 0.50 & 0.60 \\ 
   0.50 & 0.15 & 0.20 & 0.25 & 0.40 & 0.40 \\ 
   0.50 & 0.20 & 0.10 & 0.20 & 0.30 & 0.40 \\ 
   1.00 & 0.05 & 0.30 & 0.70 & 0.80 & 0.80 \\ 
   1.00 & 0.10 & 0.20 & 0.40 & 0.50 & 0.60 \\ 
   1.00 & 0.15 & 0.20 & 0.25 & 0.40 & 0.40 \\ 
   1.00 & 0.20 & 0.10 & 0.20 & 0.30 & 0.40 \\ 
   2.00 & 0.05 & 0.30 & 0.70 & 0.90 & 1.00 \\ 
   2.00 & 0.10 & 0.20 & 0.50 & 0.60 & 0.60 \\ 
   2.00 & 0.15 & 0.20 & 0.25 & 0.40 & 0.50 \\ 
   2.00 & 0.20 & 0.10 & 0.20 & 0.30 & 0.40 \\ 
   \hline
\end{tabular}
\caption{Missed detection penalties ($\phi$) as a function of $\lambda$, $\gamma$, and $\sigma$.}
\label{tab:Phi_Penalties}
\end{table}