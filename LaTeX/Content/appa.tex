Here we provide recommendations for the tuning of penalty parameters $\theta$ and $\phi$. We begin with an explanation grounded in logic. It can be shown that as the false alarm rate $\lambda$ increases, the number of expected false alarms also increases. Therefore, it stands to reason that as a general rule of thumb the false alarm penalty $\theta$ should decrease as $\lambda$ increases. Similarly, the number of expected missed detections increases as the missed detection probability $\gamma$ increases, and so too the missed detection penalty $\phi$ should decrease. Furthermore, it stands to reason that the value of both of these penalties should somehow be tied to the value of $\sigma$, since in the objective function \eqref{eq: general_objective} there is a trade-off between the estimation error, which is tied to $\sigma$, and the penalties. Therefore, in order to balance this tradeoff, we should consider increasing both penalties as $\sigma$ increases. 

Additionally, we note that missed detections are inherently correlated to the estimation error whereas false alarms are not. Therefore, $\theta$ should depend on $\lambda$ and $\sigma$ but not $\gamma$, while $\phi$ should depend on $\lambda$, $\sigma$, and $\gamma$. We also note that the estimation error of the objective function is normalized to the number of targets it is estimating, and therefore the number of missed detections is normalized as well. However, the number of false alarms has not been normalized. Thus, we suggest normalizing the penalty $\theta$ for the number of targets the MIO is currently estimating. In our case, we accomplished this normalization by tuning $\theta$ for scenarios with eight targets. We then divide $\theta$ by eight and multiply by $P_{\text{est}}$ for the current model. 

Through examination and experimentation we found these conclusions to generally hold true across a variety of scenario sizes and difficulties. Using the insight gained from these results, we tuned both penalties for the full scale experiment with detection ambiguity outlined in \mysection{\myabrv Results}. The false alarm penalties for the eight target scenarios in the robust experiment are shown in Table~\ref{tab:Theta_Penalties} and the missed detection penalties are shown in Table~\ref{tab:Phi_Penalties}.
\begin{table}[ht]
\centering
\begin{tabular}{c|m{1cm}m{1cm}m{1cm}m{1cm}}
  \hline
   & \multicolumn{4}{c}{$\sigma$} \\
   \cline{2-5}
   $\lambda$ & 0.1 & 0.5 & 1.0 & 2.0\\
  \hline
  \hline
   0.1 & 1.7 & 2.6 & 3.1 & 3.5 \\
   0.5 & 1.1 & 1.9 & 2.3 & 2.5 \\ 
   1.0 & 0.9 & 1.2 & 1.6 & 1.8 \\ 
   2.0 & 0.5 & 0.9 & 0.9 & 1.0 \\ 
   \hline
\end{tabular}
\caption{False alarm penalties ($\theta$) as a function of $\lambda$ and $\sigma$.}
\label{tab:Theta_Penalties}
\end{table}
\begin{table}[ht]
\centering
\begin{tabular}{cc|cccc}
  \hline
  & & \multicolumn{4}{c}{$\sigma$} \\
  \cline{3-6}
 $\lambda$ & $\gamma$ & 0.1 & 0.5 & 1 & 2 \\ 
  \hline
  \hline
   0.10 & 0.05 & 0.20 & 0.50 & 0.80 & 0.70 \\ 
   0.10 & 0.10 & 0.10 & 0.30 & 0.50 & 0.50 \\ 
   0.10 & 0.15 & 0.10 & 0.20 & 0.40 & 0.40 \\ 
   0.10 & 0.20 & 0.10 & 0.10 & 0.30 & 0.40 \\ 
   0.50 & 0.05 & 0.20 & 0.50 & 0.80 & 0.80 \\ 
   0.50 & 0.10 & 0.20 & 0.30 & 0.50 & 0.60 \\ 
   0.50 & 0.15 & 0.20 & 0.25 & 0.40 & 0.40 \\ 
   0.50 & 0.20 & 0.10 & 0.20 & 0.30 & 0.40 \\ 
   1.00 & 0.05 & 0.30 & 0.70 & 0.80 & 0.80 \\ 
   1.00 & 0.10 & 0.20 & 0.40 & 0.50 & 0.60 \\ 
   1.00 & 0.15 & 0.20 & 0.25 & 0.40 & 0.40 \\ 
   1.00 & 0.20 & 0.10 & 0.20 & 0.30 & 0.40 \\ 
   2.00 & 0.05 & 0.30 & 0.70 & 0.90 & 1.00 \\ 
   2.00 & 0.10 & 0.20 & 0.50 & 0.60 & 0.60 \\ 
   2.00 & 0.15 & 0.20 & 0.25 & 0.40 & 0.50 \\ 
   2.00 & 0.20 & 0.10 & 0.20 & 0.30 & 0.40 \\ 
   \hline
\end{tabular}
\caption{Missed detection penalties ($\phi$) as a function of $\lambda$, $\gamma$, and $\sigma$.}
\label{tab:Phi_Penalties}
\end{table}